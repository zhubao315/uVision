# 《王阳明心学：AI时代的认知升级课》
## 第7讲：价值对齐——训练你的"内在算法"

### 【开场】（30秒）

你有没有过这种经历？

明明知道什么是对的，但还是做了错的事；
明明清楚自己的价值观，但还是被诱惑左右。

王阳明说："心外无理，心外无物。"
也就是说，你的价值观决定了你看到的世界。

今天，我们用AI的视角，来理解"价值对齐"（Alignment）的真正含义：
它不是一个技术术语，而是你每天都在做的选择。

### 【第一部分】为什么"价值对齐"比"能力对齐"更重要？（3分钟）

很多人以为AI对齐是"让AI听话"，其实完全不是。

关键在于"让AI理解你"。

打个比方：

**能力对齐 = 做事效率**
- AI能回答你的问题
- AI能完成你的任务
- 但AI不知道你想要什么

这就像一个高效但无脑的助手：
- 你让TA查资料 → 好的
- 你让TA写报告 → 好的
- 但你真正需要的是"启发思考" → TA没听懂

**价值对齐 = 理解你**
- AI知道你的价值观
- AI知道你的长期目标
- AI的输出符合你的"本心"

这就像一个理解你的朋友：
- 你让TA查资料 → 好的（并补充背景）
- 你让TA写报告 → 好的（并指出关键问题）
- 你真正需要的是"启发思考" → TA完全懂

王阳明在《传习录》里说：

> "致良知是个大法门，千事万事，都只靠这个致良知。"

什么意思？**能力可以训练，但价值必须对齐**。
没有价值对齐的能力，就像没有方向盘的汽车：跑得越快，离目标越远。

### 【第二部分】价值对齐的三个关键步骤（3分钟）

**1. 定义你的价值观**

价值对齐的第一步，是明确你的价值观。

例子：
- 我的价值观是"长期主义"，不是"短期收益"
- 我的价值观是"真诚沟通"，不是"圆滑世故"
- 我的价值观是"持续成长"，不是"舒适安逸"

**2. 用价值观过滤选择**

价值对齐的第二步，是用价值观过滤所有选择。

例子：
- 面对高薪诱惑 → 问："这个选择符合我的'长期主义'价值观吗？"
- 面对利益冲突 → 问："这个选择符合我的'真诚沟通'价值观吗？"
- 面对舒适诱惑 → 问："这个选择符合我的'持续成长'价值观吗？"

**3. 用价值观训练"内在算法"**

价值对齐的第三步，是用日常选择训练"内在算法"。

例子：
- 每次做选择时，都按价值观思考 → 这是在"微调"
- 每次反思选择结果，都检查是否符合价值观 → 这是在"评估"
- 每次发现偏差，都及时调整 → 这是在"迭代"

这就是AI价值对齐的完整流程：
- **定义价值观（目标）** → **用价值观过滤选择** → **用选择训练"内在算法"**

### 【第三部分】如何建立价值对齐系统？（2分钟）

**1. 建立"价值观清单"**

列出你最重要的5个价值观，每次做选择前检查：
- 长期主义
- 真诚沟通
- 持续成长
- 责任感
- 爱与关怀

**2. 建立"选择检查清单"**

每次做重要选择时，按价值观清单检查：
- 这个选择符合我的"长期主义"价值观吗？
- 这个选择符合我的"真诚沟通"价值观吗？
- 这个选择符合我的"持续成长"价值观吗？

**3. 建立"价值观迭代机制"**

每季度回顾一次价值观：
- 哪些价值观依然重要？
- 哪些价值观需要调整？
- 哪些价值观可以补充？

这就是AI价值对齐的"工程化"版本：
- 个人 → 检查清单 → 迭代机制

### 【结尾】（1分钟）

"价值对齐"不是一个技术术语，而是你每天都在做的选择：

- **能力对齐 = 做事效率**（能做什么）
- **价值对齐 = 理解你**（该做什么）

为什么很多人能力很强，却活得不幸福？
因为他们只有"能力对齐"，没有"价值对齐"：
- 能力强大 ✅
- 价值观清晰 ❌
- 选择过滤 ❌
- 内在训练 ❌

而真正的幸福，是建立价值对齐闭环：
- **定义价值观 → 用价值观过滤选择 → 用选择训练"内在算法"**（AI价值对齐的完整闭环）

下节课，我们来总结整套"心学AI框架"：
- 心即理 = 建立认知框架（预训练）
- 知行合一 = 实践验证（微调）
- 致良知 = 价值对齐（训练）

（提示：这就是AI模型训练的完整闭环，也是人生进阶的底层逻辑）